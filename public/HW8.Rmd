---
title: "HW 8"
author: "SDS348 Fall 2019"
date: ""
output:
  html_document: default
  pdf_document: default
---

```{r global_options, include=FALSE}
library(knitr)
opts_chunk$set(fig.align="center", fig.height=5, message=FALSE, warning=FALSE, fig.width=8, tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

## HaoTing Huang hh25923

**This homework is due on Nov 10, 2019 at 11:59pm. Please submit as a pdf file on Canvas.**

*For all questions, include the R commands/functions that you used to find your answer. Answers without supporting code will not receive credit.*

> ### How to submit this assignment
> All homework assignments will be completed using R Markdown. These `.Rmd` files consist of text/syntax (formatted using Markdown) alongside embedded R code. 
> When you have completed the assignment (by adding R code inside codeblocks and supporting text outside of the codeblocks), create your document as follows:

> - Click the "Knit" button (above) to create an .html file
> - Open the html file in your internet browser to view
> - Go to `File > Print` and print your .html file to a .pdf
> - (or knit to PDF)
> - Upload the .pdf file to Canvas


---

### Question 1 

We will analyze some data from a famous case of alleged gender discrimination in admission to graduate programs at UC Berkeley in 1973. The three variables are `Admit` (Admitted, Rejected), `Gender` (Male, Female), and `Dept` (Departments A, B, C, D, E, F). First, create a dichotomous outcome variable $y$ that is 1 if Admit=="Admitted", 0 otherwise.

1a. (2 pts) Predict $y$ from Gender using a logistic regression. Is the effect significant? Interpret the effect: what is the odds ratio for admission to graduate school for women compared to men? Compute the predicted probability of admission for women and for men.

```{R}
library(dplyr)
# library(MASS)
library(ggplot2)
library(lmtest)
library(tidyverse)
adm<-read.csv("http://www.nathanielwoodward.com/admissions.csv")
head(adm)

dichotomous <- adm %>% select(-X) %>% mutate(y = ifelse(Admit=="Admitted",1,0))
head(dichotomous)
#adm %>% select(Dept) %>% summary()
LRQ1 <- glm(y~Gender, data = dichotomous, family = binomial(link = "logit"))

summary(LRQ1)
coeftest(LRQ1)

exp(coef(LRQ1))
table(dichotomous$y, dichotomous$Gender)
 (557/( 557+1278))/(1278/(557+1278)) # Female Odd
(1198/(1198+1493))/(1493/(1493+1198)) # Male Odd
0.8024113/0.4358372



predict(LRQ1,newdata = data.frame(Gender = "Male"), type = "response")
predict(LRQ1,newdata = data.frame(Gender = "Female"), type = "response")
```
*The effect is significant. Odds of admission for Male are 1.841 times than Female. The predicted probability of admission for women is 30.4%. the predicted probability of admission for men is 44.5%.*


1b. (2 pts) Now predict $y$ (admission) from Dept using a logistic regression. Interpret the overall pattern of results. For which departments are odds of admission higher than A? Which departments are the most selective? The least?

```{R}
LRQ1b <- glm(y~Dept, data = dichotomous, family = binomial(link = "logit"))
#summary(LRQ1b)
coef(LRQ1b)
exp(coef(LRQ1b))

#(dichotomous$y, dichotomous$Dept)

predict(LRQ1b, newdata = data.frame(Dept = "A"), type = "response") # A
predict(LRQ1b, newdata = data.frame(Dept = "B"), type = "response") # B
predict(LRQ1b, newdata = data.frame(Dept = "C"), type = "response") # C
predict(LRQ1b, newdata = data.frame(Dept = "D"), type = "response") # D
predict(LRQ1b, newdata = data.frame(Dept = "E"), type = "response") # E
predict(LRQ1b, newdata = data.frame(Dept = "F"), type = "response") # F

```

*No departments' odds are higher than A. Dept F is the most selective and the Dept A is the least selective. Student's getting more difficult to being select from Dept A to Dept F.*

1c. (2 pts) Now rerun the model but add `Dept` (Department of graduate program) as a predictor. Interpret the coefficient for `Gender` now (note there is no interaction, so the effect doesn't depend on the level of `Dept`). Controlling for Department, is there a significant effect of Gender on admissions? What is the odds ratio? What can you say about departments A and B compared to the others (in terms of odds/probability of admission; relevel if need be)?

```{R}
fit1c <-glm(y~Gender+Dept, data = dichotomous, family = "binomial")
#summary(fit1c)
coeftest(fit1c)
exp(coef(fit1c))
```

*Controlling for Department, there is no longer a significant effect of Gender on admissions (p = 0.2167). The odds ratio is 0.90. When controlling the gender, the odds of Dept A and B are way more higher than other Depts. and the odds of Dept A and Dept B are not significant different.*

1d. (2 pts) OK, now add the interaction of Gender and Department as you predict $y$ (admissions), to get a fuller picture. Compute the odds ratio for admission (Male vs. Female) in each department (A through F). Which departments favor Male applicants (i.e., higher odds of admission for Males)?

```{R}
fit1d <-glm(y~Gender+Dept+Gender*Dept, data = dichotomous, family = "binomial")
summary(fit1d)
exp(coef(fit1d))
```

*The odds ratio for GenderMale:DeptB is 2.298 times that of GenderMale:DeptA, GenderMale:DeptC is 3.24 times that of GenderMale:DeptA, GenderMale:DeptD is 2.638 times that of GenderMale:DeptA, GenderMale:DeptE is 3.498 times that of GenderMale:DeptA, GenderMale:DeptF is 2.371 times that of GenderMale:DeptA.*
*All the departments except A favor Male applicants.*

1e. (2 pts) Take the admit dataset and, using dplyr functions, create a table with counts of applicants of each Gender in each Department (e.g., number of males who applied to department A) and also the percent of applicants admitted of each Gender in each Department. Sort descending by the count variable. In terms of selectivity, what kinds of departments did the majority of women apply to? What about the majority of men? Skim through the wikipedia article about Simpson's paradox (https://en.wikipedia.org/wiki/Simpsons_paradox) to get a better idea of what is going on here!

```{R}
adm %>% select(Dept,Gender) %>% group_by(Dept,Gender)%>% summarise(count= n())


# table1e$percent <- adm 
adm %>% select(Dept,Gender) %>% group_by(Dept,) %>% count(Gender) %>% mutate(total = sum(n))%>% group_by(Gender) %>% mutate(per=paste0(round(100*n/total,2),'%')) %>% arrange(desc(n))
```
*the majority of women applied to C,D,E, and F and in terms of selective, C,D,E and F were more selective than A,B, which were the department that most men applied to.*

## Question 2

Load the starswars data (from the dplyr package). Remove all NAs from the variables `mass`, `height`, and `species`.  Create a binary numeric variable $y$: 1 if species is Human, 0 otherwise. Use this modified dataset for the remaining questions.

2a (3 pts) Predict the dichotomous Human indicator (`y`) from `height` using a logistic regression. Briefly interpret. Plot the ROC curve and compute the AUC. Create a plot of the logistic regression showing predicted probability of being Human by height. Color points by predicted human vs predicted not.

```{R}
data(starwars)
library(plotROC)
starwarsWithoutNA <-starwars %>%drop_na(mass, height, species) %>% mutate(y= ifelse(species == "Human", 1, 0))

head(starwarsWithoutNA)

fit2a <-glm(y ~ height, data = starwarsWithoutNA, family = binomial)
coef(fit2a)

exp(coef(fit2a))


# ROC + AUC
starwarsWithoutNA$prob <-predict(fit2a, type = "response")
ggplot(starwarsWithoutNA) +geom_roc(aes(d = y, m = prob), n.cuts = 0)

calc_auc((ggplot(starwarsWithoutNA) +geom_roc(aes(d = y, m = prob), n.cuts = 0)))


# LR plot
ggplot(starwarsWithoutNA, aes(height, prob)) + geom_point(aes(color = y))
```

*According to the ROC cruve and logistic regression plot, it's hard to predcit whether as species is a human by its height.*

2b. (2 pts) Predict the Human indicator variable (`y`) from `height` and `mass` (no interaction). Discuss the output briefly (you do not have to interpret any coeficients). Compute Accuracy, Sensitivity, and Specificity. Plot the ROC curve and compute the AUC.

```{R}
fit2b <-glm(y~ height + mass, data = starwarsWithoutNA, family = binomial(link = "logit"))
summary(fit2b)
exp(coef(fit2b))

prob2b <- predict(fit2b, type = "response")
pred2b <-ifelse(prob2b >0.5,1,0)
table(truth = starwarsWithoutNA$y, prediction = pred2b) %>% addmargins

# accuracy
36/58

#tpr 
0

#tnr
36/36

#ROC + AUC
starwarsWithoutNA$prob2b <- predict(fit2b, type = "response")
ROC2b <-ggplot(starwarsWithoutNA) + geom_roc(aes(d = y, m = prob2b), n.cuts = 0)
ROC2b

calc_auc(ROC2b)
```

*Based on the ROC polt and logistic regression, there's no significant difference in height between human and other speices and also no significant difference in mass between human and other species.Accuracy = 0.6206897, Sensitivity = 0, and Specificity = 1. AUC = 0.469697.*

2c. (3 pts) Predict this variable from the interaction of height and mass. Be sure to center your variables first, and save them to the starwars dataset as `mass_c` and `height_c`. Discuss the output. Compute Accuracy, Sensitivity, and Specificity. Plot the ROC curve and calculate the AUC. Compare the AUC with that of the main-effects model in 2b.

```{R}
starwarsWithoutNA$massCenter <- starwarsWithoutNA$mass - mean(starwarsWithoutNA$mass)
starwarsWithoutNA$heightCenter <-starwarsWithoutNA$height - mean(starwarsWithoutNA$height)


fit2c <-glm(y ~ heightCenter * massCenter, data = starwarsWithoutNA, family = binomial)
summary(fit2c)
coeftest(fit2c)
exp(coef(fit2c))

prob2c <-predict(fit2c, type="response")
pred2c <- ifelse(prob2c >0.5, 1,0)
table(truth = starwarsWithoutNA$y, prediction = pred2c) %>% addmargins()

# accuracy
(25+6)/58

# tpr
 6/17
 
 #tnr
 25/41
 
# ROC + AUC
ROC2c <- ggplot(starwarsWithoutNA) + geom_roc(aes( d = y, m = prob2c),n.cuts = 0)
ROC2c
calc_auc(ROC2c)
```

*According to the logistic regression, the interaction between heightCenter and massCenter is significant (p < 0.05). Accuracy = 0.5344828, Sensitivity = 0.3529412, and Specificity = 0.6097561. AUC = 0.6287879.*

2d. (2 pts) We want to visualize the interaction, but it is continuous! We can get around this by setting mass_c to the mean (0) and plus/minus one standard deviation and then looking at the effect of height on the probability of being human. Below, in the code given, I take the starwars dataset and I duplicate it three times: to one, I add a column with `mass_c=0`, to another, I add `mass_c=sd(mass)`, and to the third I add `mass_c=-sd(mass)`. I stack them all on top of each other and add a label (`mass_cat`). Use this new dataset and `predict(..., newdata=starwars_new, type="response")` to get predicted probabilities from your interaction model, and then use ggplot to plot those predicted probabilities against height (use geom_line and set `color=mass_cat`). What do you see?

```{R}
## Code to get you started on 2d
starwars_new<-bind_rows(mutate(starwarsWithoutNA,massCenter=0),
                     mutate(starwarsWithoutNA,massCenter=sd(mass)),
                     mutate(starwarsWithoutNA,massCenter=-sd(mass)))

starwars_new<-starwars_new%>%
  mutate(mass_cat=c(rep("mean",nrow(starwarsWithoutNA)),
                    rep("mean+1sd",nrow(starwarsWithoutNA)),
                    rep("mean-1sd",nrow(starwarsWithoutNA))))


prob2d <- predict(fit2c, newdata = starwars_new, type = "response")

plot2d <-ggplot(starwars_new, aes(heightCenter, prob2d)) + geom_line(aes(color=mass_cat))
plot2d
```
*The height is negative associated with the species human. I can see the interaction of mean, mean-1sd and mean+1sd joint at heightCenter = 0 and prob2d = 0.5.*

```{R, echo=F}
## DO NOT DELETE THIS BLOCK!
sessionInfo()
Sys.time()
Sys.info()
```